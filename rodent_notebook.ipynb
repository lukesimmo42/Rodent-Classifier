{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25411f8e-05f9-43fb-bd66-3f68c95cd4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -Uqq fastbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3886ab9",
   "metadata": {
    "gradient": {
     "editing": true,
     "execution_count": 1,
     "id": "e3886ab9",
     "kernelId": "337d1aca-c0fa-4d04-849c-91cc3285fdcc"
    }
   },
   "outputs": [],
   "source": [
    "from fastbook import *\n",
    "from fastai.vision.widgets import *\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68acdd4b",
   "metadata": {
    "gradient": {
     "execution_count": 3,
     "id": "68acdd4b",
     "kernelId": "337d1aca-c0fa-4d04-849c-91cc3285fdcc"
    }
   },
   "outputs": [],
   "source": [
    "key = os.environ.get('AZURE_SEARCH_KEY', 'XXX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23b8038",
   "metadata": {
    "gradient": {
     "editing": true,
     "execution_count": 75,
     "id": "c23b8038",
     "kernelId": "337d1aca-c0fa-4d04-849c-91cc3285fdcc"
    }
   },
   "outputs": [],
   "source": [
    "# get list of rodents\n",
    "with open('rodent_names_reduced.csv') as file_name:\n",
    "    rodent_names = next(csv.reader(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e630c5e",
   "metadata": {
    "gradient": {
     "execution_count": 79,
     "id": "9e630c5e",
     "kernelId": "337d1aca-c0fa-4d04-849c-91cc3285fdcc"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = Path('images')\n",
    "\n",
    "# for each rodent: download images of it has no image folder\n",
    "for o in rodent_names:\n",
    "    if not (path/o).exists():\n",
    "        print(o)\n",
    "        dest = (path/o)\n",
    "        dest.mkdir(exist_ok=True)\n",
    "        results = search_images_bing(key, f'{o} rodent')\n",
    "        download_images(dest, urls=results.attrgot('contentUrl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4407516c",
   "metadata": {
    "gradient": {
     "editing": true,
     "execution_count": 94,
     "id": "4407516c",
     "kernelId": "337d1aca-c0fa-4d04-849c-91cc3285fdcc"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get list of images that can't be opened\n",
    "fns = get_image_files(path)\n",
    "failed = False\n",
    "failed = verify_images(fns)\n",
    "failed\n",
    "\n",
    "# delete those images\n",
    "if failed:\n",
    "    failed.map(Path.unlink);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41cd586-2f54-48a9-962c-6ced073dc3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non-images and convert images to RGBA\n",
    "# (we do this because the pretrained model we will use was trained with RGBA images)\n",
    "for file in os.listdir(path):\n",
    "    for image in os.listdir(path/file):\n",
    "        if not image.startswith('.'):\n",
    "            try:\n",
    "                im = Image.open(path/file/image)\n",
    "            except:\n",
    "                try:\n",
    "                    os.remove(path/file/image)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "            if im.format == 'PNG':\n",
    "                if im.mode != 'RGBA':\n",
    "                    try:\n",
    "                        im.convert('RGBA').save(path/file/image)\n",
    "                    except:\n",
    "                        os.remove(path/o/image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abb3367",
   "metadata": {
    "gradient": {
     "editing": true,
     "execution_count": 86,
     "id": "6abb3367",
     "kernelId": "337d1aca-c0fa-4d04-849c-91cc3285fdcc"
    }
   },
   "outputs": [],
   "source": [
    "#create datablock object\n",
    "rodents_db = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock), \n",
    "    get_items=get_image_files, \n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=RandomResizedCrop(224, min_scale=0.5),\n",
    "    batch_tfms=aug_transforms()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aa2410",
   "metadata": {
    "gradient": {
     "execution_count": 87,
     "id": "e8aa2410",
     "kernelId": "337d1aca-c0fa-4d04-849c-91cc3285fdcc"
    }
   },
   "outputs": [],
   "source": [
    "# create dataloaders object from datablock\n",
    "dls = rodents_db.dataloaders(path)\n",
    "# this object contains a training data loader and a validation data loader\n",
    "# a dataloader is an object that passes batches of a few items at a time to the GPU\n",
    "# i.e. we use a data loader to pass image files to the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0917f65",
   "metadata": {
    "gradient": {
     "execution_count": 88,
     "id": "a0917f65",
     "kernelId": "337d1aca-c0fa-4d04-849c-91cc3285fdcc"
    }
   },
   "outputs": [],
   "source": [
    "# show batch of four images from validation datablock things are ok\n",
    "dls.valid.show_batch(max_n=4, nrows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab89dbd",
   "metadata": {
    "gradient": {
     "execution_count": 120,
     "id": "cab89dbd",
     "kernelId": "337d1aca-c0fa-4d04-849c-91cc3285fdcc"
    }
   },
   "outputs": [],
   "source": [
    "# create deep learning model that:\n",
    "# uses our dataloaders object to fetch data from,\n",
    "# uses initial parameters of the resnet18 model,\n",
    "# displays error_rate as human readable measure of accuracy\n",
    "learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
    "\n",
    "# run through batches of the training set, for each batch, \n",
    "# slightly tweak the paramters of the model to decrease whatever the loss function is for that batch\n",
    "# (loss_function was chosen automatically in previous line)\n",
    "learn.fine_tune(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ac46f5",
   "metadata": {
    "gradient": {
     "execution_count": 127,
     "id": "61ac46f5",
     "kernelId": "337d1aca-c0fa-4d04-849c-91cc3285fdcc"
    }
   },
   "outputs": [],
   "source": [
    "# create and display matrix showing which images were mistaken for a different species\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix(figsize=(30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c44479-c1a2-4888-91a1-31042c470dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open cleaner utility which lets us remove innacurately classified images from the dataset\n",
    "cleaner = ImageClassifierCleaner(learn)\n",
    "cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed480188-9dba-41fc-a7d4-87fd84d991e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete images we chose to remove\n",
    "for idx in cleaner.delete(): cleaner.fns[idx].unlink()\n",
    "for idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat)\n",
    "# we could now train our model again (from scratch) to get more accurate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08356757-d4af-4b07-8185-becc701c9af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the model\n",
    "learn.export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
